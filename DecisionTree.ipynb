{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "290120b4-a741-467b-8574-bcd38b98761b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "CLEAN THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc47e43-4d68-4965-88ff-63e056c1e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#load file\n",
    "dataset = pd.read_csv(r\"./Dataset/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c000dd-e29c-42cd-9f78-9160e7fb50fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease</th>\n",
       "      <th>Symptom_1</th>\n",
       "      <th>Symptom_2</th>\n",
       "      <th>Symptom_3</th>\n",
       "      <th>Symptom_4</th>\n",
       "      <th>Symptom_5</th>\n",
       "      <th>Symptom_6</th>\n",
       "      <th>Symptom_7</th>\n",
       "      <th>Symptom_8</th>\n",
       "      <th>Symptom_9</th>\n",
       "      <th>Symptom_10</th>\n",
       "      <th>Symptom_11</th>\n",
       "      <th>Symptom_12</th>\n",
       "      <th>Symptom_13</th>\n",
       "      <th>Symptom_14</th>\n",
       "      <th>Symptom_15</th>\n",
       "      <th>Symptom_16</th>\n",
       "      <th>Symptom_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>itching</td>\n",
       "      <td>skin_rash</td>\n",
       "      <td>nodal_skin_eruptions</td>\n",
       "      <td>dischromic_patches</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fungal infection</td>\n",
       "      <td>skin_rash</td>\n",
       "      <td>nodal_skin_eruptions</td>\n",
       "      <td>dischromic_patches</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Disease  Symptom_1             Symptom_2             Symptom_3  \\\n",
       "0  Fungal infection    itching             skin_rash  nodal_skin_eruptions   \n",
       "1  Fungal infection  skin_rash  nodal_skin_eruptions    dischromic_patches   \n",
       "\n",
       "            Symptom_4 Symptom_5 Symptom_6 Symptom_7 Symptom_8 Symptom_9  \\\n",
       "0  dischromic_patches       NaN       NaN       NaN       NaN       NaN   \n",
       "1                 NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "  Symptom_10 Symptom_11 Symptom_12 Symptom_13 Symptom_14 Symptom_15  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "  Symptom_16 Symptom_17  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(x):                                                                            #we define a \"cleaning\" function which removes any spaces in front or after the string\n",
    "    if isinstance(x, str):                                                                    #Check if (object,type)\n",
    "        return x.strip().replace(\"  \", \" \").replace(\" _\", \"_\").replace(\"_ \", \"_\")             #eemove spaces from both ends of the string\n",
    "    else:\n",
    "        return x  \n",
    "\n",
    "\n",
    "# apply the function to each column\n",
    "for col in dataset.columns:\n",
    "    dataset[col] = dataset[col].map(clean_data)\n",
    "\n",
    "    \n",
    "#check the output\n",
    "dataset.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44181fd7-9cd3-4b9a-b979-6faaf96e04b0",
   "metadata": {},
   "source": [
    "CHECKLIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37effd24-5915-4840-b676-4c135c72dc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique symptoms: 131\n",
      "Symptoms: ['abdominal_pain', 'abnormal_menstruation', 'acidity', 'acute_liver_failure', 'altered_sensorium', 'anxiety', 'back_pain', 'belly_pain', 'blackheads', 'bladder_discomfort', 'blister', 'blood_in_sputum', 'bloody_stool', 'blurred_and_distorted_vision', 'breathlessness', 'brittle_nails', 'bruising', 'burning_micturition', 'chest_pain', 'chills', 'cold_hands_and_feets', 'coma', 'congestion', 'constipation', 'continuous_feel_of_urine', 'continuous_sneezing', 'cough', 'cramps', 'dark_urine', 'dehydration', 'depression', 'diarrhoea', 'dischromic_patches', 'distention_of_abdomen', 'dizziness', 'drying_and_tingling_lips', 'enlarged_thyroid', 'excessive_hunger', 'extra_marital_contacts', 'family_history', 'fast_heart_rate', 'fatigue', 'fluid_overload', 'foul_smell_of urine', 'headache', 'high_fever', 'hip_joint_pain', 'history_of_alcohol_consumption', 'increased_appetite', 'indigestion', 'inflammatory_nails', 'internal_itching', 'irregular_sugar_level', 'irritability', 'irritation_in_anus', 'itching', 'joint_pain', 'knee_pain', 'lack_of_concentration', 'lethargy', 'loss_of_appetite', 'loss_of_balance', 'loss_of_smell', 'malaise', 'mild_fever', 'mood_swings', 'movement_stiffness', 'mucoid_sputum', 'muscle_pain', 'muscle_wasting', 'muscle_weakness', 'nausea', 'neck_pain', 'nodal_skin_eruptions', 'obesity', 'pain_behind_the_eyes', 'pain_during_bowel_movements', 'pain_in_anal_region', 'painful_walking', 'palpitations', 'passage_of_gases', 'patches_in_throat', 'phlegm', 'polyuria', 'prominent_veins_on_calf', 'puffy_face_and_eyes', 'pus_filled_pimples', 'receiving_blood_transfusion', 'receiving_unsterile_injections', 'red_sore_around_nose', 'red_spots_over_body', 'redness_of_eyes', 'restlessness', 'runny_nose', 'rusty_sputum', 'scurring', 'shivering', 'silver_like_dusting', 'sinus_pressure', 'skin_peeling', 'skin_rash', 'slurred_speech', 'small_dents_in_nails', 'spinning_movements', 'spotting_urination', 'stiff_neck', 'stomach_bleeding', 'stomach_pain', 'sunken_eyes', 'sweating', 'swelled_lymph_nodes', 'swelling_joints', 'swelling_of_stomach', 'swollen_blood_vessels', 'swollen_extremeties', 'swollen_legs', 'throat_irritation', 'toxic_look_(typhos)', 'ulcers_on_tongue', 'unsteadiness', 'visual_disturbances', 'vomiting', 'watering_from_eyes', 'weakness_in_limbs', 'weakness_of_one_body_side', 'weight_gain', 'weight_loss', 'yellow_crust_ooze', 'yellow_urine', 'yellowing_of_eyes', 'yellowish_skin']\n"
     ]
    }
   ],
   "source": [
    "#we now will make the checklist of all symptoms\n",
    "#List of symptom columns\n",
    "symptom_cols = [\n",
    "    'Symptom_1', 'Symptom_2', 'Symptom_3', 'Symptom_4', 'Symptom_5',\n",
    "    'Symptom_6', 'Symptom_7', 'Symptom_8', 'Symptom_9', 'Symptom_10',\n",
    "    'Symptom_11', 'Symptom_12', 'Symptom_13', 'Symptom_14', 'Symptom_15',\n",
    "    'Symptom_16', 'Symptom_17'\n",
    "]\n",
    "#create the empty list to store all symptoms\n",
    "all_symptoms = []\n",
    "\n",
    "for col in symptom_cols:                           # go through each Symptom_1 to Symptom_17 column\n",
    "    for symptom in dataset[col]:                   # go through every value in that column\n",
    "        if pd.notna(symptom):                      # check if the cell is not nan\n",
    "            all_symptoms.append(symptom)           # add it to the list\n",
    "\n",
    "unique_symptoms = sorted(list(set(all_symptoms)))  #to remove the duplicates with set, we make them again a list (makes it usable for indexing and loops) and we soort them alphabetically in order to read them easier\n",
    "\n",
    "\n",
    "#print how many symptoms we found\n",
    "print(\"Number of unique symptoms:\", len(unique_symptoms))\n",
    "print(\"Symptoms:\", unique_symptoms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2593919-325e-4b23-8925-e505cd8bbe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       0\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "4915    0\n",
      "4916    0\n",
      "4917    0\n",
      "4918    0\n",
      "4919    0\n",
      "Name: itching, Length: 4920, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3929252937.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Assume you want to keep the original disease/diagnosis column\n",
    "#Each unique symptom becomes column, instead of writing symptom names, we have 1 if patient has the syptom and 0 if not\n",
    "\n",
    "\n",
    "binary = pd.DataFrame()                  #Create a new, empty table (DataFrame) named binary to hold the simplified data\n",
    "binary['Disease'] = dataset['Disease']  #Copy the disease column from the original dataset (dataset) into the binary table\n",
    "\n",
    "#for each syptom we check ecah row\n",
    "for symptom in unique_symptoms:\n",
    "    binary[symptom] = dataset[symptom_cols].eq(symptom).any(axis=1).astype(int)\n",
    "#so what we basically did : For each symptom in your list, check every patient.Mark 1 if the patient has this symptom anywhere, or 0 if not\n",
    "\n",
    "#check the \n",
    "print(binary['itching'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774fd509-a380-4096-b6a7-a34cbad39544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       6\n",
      "1       6\n",
      "2       6\n",
      "3       6\n",
      "4       0\n",
      "       ..\n",
      "4915    0\n",
      "4916    0\n",
      "4917    0\n",
      "4918    0\n",
      "4919    0\n",
      "Name: dischromic_patches, Length: 4920, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_11300\\3318896304.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0)\n"
     ]
    }
   ],
   "source": [
    "#severity score encoding --> Instead of using 1 for \"symptom present\", we now use a severity score like 3, 4, or 5 (based on the symptom’s usual intensity)\n",
    "\n",
    "# Load severity score\n",
    "severity = pd.read_csv(r\"./Dataset/symptom_severity.csv\")\n",
    "\n",
    "severity.head(4)\n",
    "\n",
    "severity_dict = dict(zip(severity['Symptom'], severity['weight'])) #creates a dictionary from the table\n",
    "\n",
    "# Create a new copy of the dataset for severity version\n",
    "severity_w = pd.DataFrame()\n",
    "severity_w['Disease'] = dataset['Disease']\n",
    "\n",
    "# Fill with weights instead of 1s\n",
    "for symptom in unique_symptoms:\n",
    "    # Check if each symptom is present\n",
    "    symptom_present = dataset[symptom_cols].eq(symptom).any(axis=1)\n",
    "\n",
    "    # Replace True with severity weight, False with 0\n",
    "    severity_w[symptom] = symptom_present.astype(int) * severity_dict.get(symptom, 0) \n",
    "\n",
    "#check the output\n",
    "print(severity_w['dischromic_patches']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "413fce5d-cbaf-4736-be7e-f32d6e5e06e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease                  Chronic cholestasis\n",
      "abdominal_pain                             4\n",
      "abnormal_menstruation                      0\n",
      "acidity                                    0\n",
      "acute_liver_failure                        0\n",
      "                                ...         \n",
      "weight_loss                                0\n",
      "yellow_crust_ooze                          0\n",
      "yellow_urine                               0\n",
      "yellowing_of_eyes                          4\n",
      "yellowish_skin                             3\n",
      "Name: 32, Length: 132, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(severity_w.iloc[32])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d47459-0aab-4559-8bb7-7369d928972a",
   "metadata": {},
   "source": [
    "LETS TRAIN BOTH NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05281daf-bf15-4d33-919f-a8efa2181317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2c662-05b3-486a-85e9-aa826489f37e",
   "metadata": {},
   "source": [
    "MODEL 1(BINARY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b57d5-93e2-46c0-ba30-db453f281e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Urinary tract infection' 'Diabetes' 'Hepatitis D' 'Psoriasis'\n",
      " 'Alcoholic hepatitis' 'Alcoholic hepatitis'\n",
      " 'Dimorphic hemmorhoids(piles)' 'Hepatitis E' 'Diabetes'\n",
      " 'Cervical spondylosis']\n",
      "2662         Urinary tract infection\n",
      "3697                        Diabetes\n",
      "3630                     Hepatitis D\n",
      "1215                       Psoriasis\n",
      "1888             Alcoholic hepatitis\n",
      "1471             Alcoholic hepatitis\n",
      "4210    Dimorphic hemmorhoids(piles)\n",
      "4451                     Hepatitis E\n",
      "1718                        Diabetes\n",
      "3948            Cervical spondylosis\n",
      "Name: Disease, dtype: object\n",
      "Binary Encoding Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "#Prepare the data\n",
    "X_binary = binary.drop(columns=['Disease'])  # All columns except Disease\n",
    "y_binary = binary['Disease']  # Target column\n",
    "\n",
    "#Split the data\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(X_binary, y_binary, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Create and train the Decision Tree model\n",
    "dt_model_binary = DecisionTreeClassifier(random_state=42)\n",
    "dt_model_binary.fit(X_train_bin, y_train_bin)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_binary = dt_model_binary.predict(X_test_bin)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_binary = accuracy_score(y_test_bin, y_pred_binary)\n",
    "print(f\"Binary Encoding Accuracy: {accuracy_binary * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6eceee08-2dc1-484e-935a-778de10166e6",
   "metadata": {},
   "source": [
    "with 100% accuracy obviously something wrong.. maybe overfitting??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f77f85-9f39-491f-aff6-00a4c17ff2d6",
   "metadata": {},
   "source": [
    "MODEL 2 (SEVERITY SCORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8dd1f46-ce70-45f8-a3b4-fa582133d5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity Encoding Accuracy: 95.26 %\n"
     ]
    }
   ],
   "source": [
    "#prepare data\n",
    "X_severity = severity_w.drop(columns=['Disease'])  # Dropping target column\n",
    "y_severity = severity_w['Disease']  # Target column (disease)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_severity, X_test_severity, y_train_severity, y_test_severity = train_test_split(X_severity, y_severity, test_size=0.9, random_state=42)\n",
    "\n",
    "# Create and train the Decision Tree model\n",
    "dt_model_severity = DecisionTreeClassifier(random_state=42)\n",
    "dt_model_severity.fit(X_train_severity, y_train_severity)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_severity = dt_model_severity.predict(X_test_severity)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_severity = accuracy_score(y_test_severity, y_pred_severity)\n",
    "print(f\"Severity Encoding Accuracy: {accuracy_severity * 100:.2f} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f57acec-ad9b-4ffa-a114-94576f377471",
   "metadata": {},
   "source": [
    "hmmmm..i dont know what the **** is going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6dd88a-2d81-402d-a959-6311e35518ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get learning curve data\n",
    "train_sizes, train_scores, test_scores = learning_curve(dt_model_binary, X_train_bin, y_train_bin, cv=5, scoring='accuracy')\n",
    "train_sizes_w, train_scores_w, test_scores_w = learning_curve(dt_model_severity, X_train_severity, y_train_severity, cv=5, scoring='accuracy')\n",
    "# Create the plots side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot learning curve for binary\n",
    "axes[0].plot(train_sizes, train_scores.mean(axis=1), label='Training Accuracy')\n",
    "axes[0].plot(train_sizes, test_scores.mean(axis=1), label='Test Accuracy')\n",
    "axes[0].set_title('Learning Curve - Binary Encoding')\n",
    "axes[0].set_xlabel('Training Set Size')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot learning curve for severity_w\n",
    "axes[1].plot(train_sizes_w, train_scores_w.mean(axis=1), label='Training Accuracy')\n",
    "axes[1].plot(train_sizes_w, test_scores_w.mean(axis=1), label='Test Accuracy')\n",
    "axes[1].set_title('Learning Curve - Severity Weighted Encoding')\n",
    "axes[1].set_xlabel('Training Set Size')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4819dd23-fec5-4fe9-b3af-a80f8466fbbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697fa29e-ed07-44fe-8ef1-112f44eccffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Perform cross-validation with 5 folds\n",
    "cv_scores = cross_val_score(dt_model_binary, X_binary, y_binary, cv=5, scoring='accuracy')\n",
    "\n",
    "# Output the cross-validation scores for each fold\n",
    "print(f\"Cross-Validation Accuracy for each fold: {cv_scores}\")\n",
    "print(f\"Mean Cross-Validation Accuracy: {cv_scores.mean():.4f}\")\n",
    "print(f\"Standard Deviation of Accuracy: {cv_scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950668a8-77a7-4515-8727-691bf4d4efcf",
   "metadata": {},
   "source": [
    "sure for overfitting (we have small dataset and probably model memorizes the training data) --> use a more complex model like random forest\n",
    "assume that DT is overly simple thats why \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbee1ba-985b-4bc1-bbe2-764bf5bc74e8",
   "metadata": {},
   "source": [
    "i tried playing with the depth of the models and if you put it to 5 per say , the accuraccy of the model goes to ~10% or something \n",
    "so what if we tried an play with the depth because DT seems to go in great depth and thats the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46429cd6-e1a3-4ea4-9cec-06c2bb43c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for max_depth to search\n",
    "param_grid = {\n",
    "    'max_depth': range(5,51,5)  # At 60 it goes up to 100% again \n",
    "}\n",
    "\n",
    "    \n",
    "# Grid search to find the best max_depth (hyperparameter tunning)\n",
    "grid_search_binary = GridSearchCV(estimator=dt_model_binary, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_binary.fit(X_binary, y_binary)\n",
    "\n",
    "grid_search_severity_w = GridSearchCV(estimator=dt_model_severity, param_grid = param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_severity_w.fit(X_severity, y_severity)\n",
    "# Best depth and its accuracy\n",
    "best_depth_binary = grid_search_binary.best_params_['max_depth']\n",
    "best_accuracy_binary = grid_search_binary.best_score_\n",
    "print(best_depth_binary, best_accuracy_binary)\n",
    "\n",
    "best_depth_severity_w = grid_search_severity_w.best_params_['max_depth']\n",
    "best_accuracy_severity_w = grid_search_severity_w.best_score_\n",
    "print(best_depth_severity_w, best_accuracy_severity_w)\n",
    "\n",
    "\n",
    "#plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "#for binary\n",
    "axes[0].plot(param_grid['max_depth'], grid_search_binary.cv_results_['mean_test_score'], 'bo-', label='Binary Encoding Accuracy')\n",
    "axes[0].set_title('Grid Search - Max Depth vs Accuracy\\nBinary Encoding')\n",
    "axes[0].set_xlabel('Max Depth')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "\n",
    "# for Severity Weighted Encoding\n",
    "axes[1].plot(param_grid['max_depth'], grid_search_severity_w.cv_results_['mean_test_score'], 'bo-', label='Binary Encoding Accuracy')\n",
    "axes[1].set_title('Grid Search - Max Depth vs Accuracy\\nSeverity Weighted Encoding')\n",
    "axes[1].set_xlabel('Max Depth')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3665aa8-df7c-40cb-9dd5-6d77ee426c4c",
   "metadata": {},
   "source": [
    "as it seems this approach doesnt seem exactly to roll \n",
    "but in the dataset we have same disases with similar symptoms or same symptoms+1 more , so maybe we could optimizd the DT approach by groupping the same diseases together --> reduced layers --> better generalization --> not overfitting??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
